{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Simple Network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathdata = \"../data/\"\n",
    "\n",
    "cnames = ['centerIm', 'leftIm','rightIm','steer','throttle','brake','speed']\n",
    "df = pd.read_csv(pathdata+\"driving_log.csv\", names=cnames)\n",
    "# df.head()\n",
    "\n",
    "# Read center image\n",
    "xCenter = df['centerIm']\n",
    "xLeft  = df['leftIm']\n",
    "xRight = df['rightIm']\n",
    "ysteer = df['steer']\n",
    "del df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple (camera) images as input\n",
    "def read3camerasImg(pathCenter, pathLeft, pathRight, steering, steerAdj = 0.2):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        \"pathCenter\", \"pathLeft\" and \"pathRight\" are all (nx1) vector of strings, containing the path\n",
    "        of the saved image\n",
    "        example: pathCenter[0], pathLeft[0] and pathRight[0]\n",
    "        C:\\SelfDrivingCarNanodegree\\3BehavioralCloning\\data\\IMG\\center_2018_04_05_13_39_08_155.jpg\n",
    "        C:\\SelfDrivingCarNanodegree\\3BehavioralCloning\\data\\IMG\\left_2018_04_05_13_39_08_155.jpg\n",
    "        C:\\SelfDrivingCarNanodegree\\3BehavioralCloning\\data\\IMG\\right_2018_04_05_13_39_08_155.jpg\n",
    "        \n",
    "        \"steering\" is a vector of double for the steering angle. Left steering is positive, right is negative\n",
    "        example: steeing[0] = -0.36\n",
    "    output:\n",
    "        X, images in numpy array of (n, h, w, d)\n",
    "        y, steer value in numpy array of size (n, )\n",
    "    \n",
    "    \"\"\"\n",
    "    assert len(pathCenter) == len(pathLeft) == len(pathRight) == len(steering)\n",
    "    images3 = []\n",
    "    steer = []\n",
    "\n",
    "    nim = len(xCenter)\n",
    "    for i in range(nim):\n",
    "        imgC = cv.cvtColor(cv.imread(xCenter[i]), cv.COLOR_BGR2RGB)\n",
    "        imgL = cv.cvtColor(cv.imread(xLeft[i]), cv.COLOR_BGR2RGB)\n",
    "        imgR = cv.cvtColor(cv.imread(xRight[i]), cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        # convert \n",
    "        # correct steering angle (y) for lect image and right image\n",
    "        yC = steering[i]\n",
    "        yL = steering[i] + steerAdj\n",
    "        yR = steering[i] - steerAdj\n",
    "        images3.extend([imgC, imgL, imgR])\n",
    "        steer.extend([yC, yL, yR])\n",
    "        if (i%1000==0): print(\"Images imported: \" + str(i) + \"x 3\")\n",
    "        \n",
    "    y = np.array(steer)\n",
    "    X = np.array(images3)\n",
    "    \n",
    "    return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipBatchImg(images, measurement):\n",
    "    \"\"\"\n",
    "    Create a new Augment batch images with flipped image\n",
    "    Input:  images:          (n, w, d, 3)\n",
    "            measurement:     (n, )\n",
    "    \"\"\"\n",
    "    # data augmentation: Flipped image\n",
    "    \n",
    "    assert images.shape[0] == measurement.shape[0]\n",
    "    \n",
    "    fImages = []\n",
    "    fMeasurement = []\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        image_flipped = np.fliplr(img)\n",
    "        measurement_flipped = - measurement[i]\n",
    "        fImages.append(image_flipped)\n",
    "        fMeasurement.append(measurement_flipped)\n",
    "        if (i%1000==0): print(\"Images flipped: \" + str(i))\n",
    "        \n",
    "    newImages = np.array(fImages)\n",
    "    newMeasurement = np.array(fMeasurement)\n",
    "        \n",
    "    return newImages, newMeasurement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # impath = xCenter[0]\n",
    "# # img = cv.imread(impath)\n",
    "# images = []\n",
    "# for i, ipath in enumerate(xCenter):\n",
    "#     img = cv.imread(ipath)\n",
    "#     images.append(img)\n",
    "# #     print(i, img)\n",
    "\n",
    "# X = np.array(images)\n",
    "# y = np.array(y)\n",
    "# # plt.imshow(img)\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "\n",
    "# timg = cv.imread(xCenter[100])\n",
    "# ## red and blue colors are inverted\n",
    "# timg2 = cv.cvtColor(timg, cv.COLOR_RGB2BGR)\n",
    "    \n",
    "# timg3 = cv.cvtColor(timg, cv.COLOR_BGR2RGB)\n",
    "\n",
    "# timg4 =  cv.cvtColor(cv.imread(xCenter[3]), cv.COLOR_BGR2RGB)\n",
    "# plt.imshow(timg4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nim = len(xCenter)\n",
    "# t1 = []\n",
    "# t2 = []\n",
    "# for i in range(nim):\n",
    "#     yC = ysteer[i]\n",
    "#     yL = ysteer[i] + 0.2\n",
    "#     yR = ysteer[i] - 0.2\n",
    "#     t1.extend([yC, yL, yR])\n",
    "#     t2.append([yC, yL, yR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "# print(X_train.shape)\n",
    "# print(X_val.shape)\n",
    "# print(y_train.shape)\n",
    "\n",
    "print(np.array(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images imported: 0x 3\n",
      "Images imported: 1000x 3\n",
      "Images imported: 2000x 3\n",
      "Images imported: 3000x 3\n",
      "Images imported: 4000x 3\n",
      "Images imported: 5000x 3\n",
      "Images imported: 6000x 3\n",
      "Images imported: 7000x 3\n",
      "Images imported: 8000x 3\n",
      "Images imported: 9000x 3\n"
     ]
    }
   ],
   "source": [
    "X, y = read3camerasImg(xCenter, xLeft, xRight, steering=ysteer, steerAdj=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if SAVE:\n",
    "#         save_path = saver.save(sess, MODEL_PATH)\n",
    "#         print('Trained model saved at: %s' % save_path)\n",
    "#         # Save accuracy history\n",
    "#         print('Accuracy history saved at accuracy_history.p')\n",
    "#         with open('accuracy_history.p', 'wb') as f:\n",
    "#             pickle.dump(accuracy_history, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "n = X.shape[0]\n",
    "\n",
    "#sample without replacement. add 1/4 sample where each image is flipped\n",
    "select = sample(range(n), int(n/4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27300, 160, 320, 3)\n",
      "(27300,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Save example images in example directory\n",
    "expath = \"example/\"\n",
    "if not os.path.isdir(expath): os.makedirs(expath)\n",
    "\n",
    "# Note: cv has default BGR. As I read with BGR and write with BGR, no need of color conversion\n",
    "imgC = cv.imread(xCenter[123])\n",
    "imgL = cv.imread(xLeft[123])\n",
    "imgR = cv.imread(xRight[123])\n",
    "cv.imwrite(expath + \"cameraLeft.png\", imgL)\n",
    "cv.imwrite(expath + \"cameraRight.png\", imgR)\n",
    "cv.imwrite(expath + \"cameraCenter.png\", imgC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images flipped: 0\n",
      "Images flipped: 1000\n",
      "Images flipped: 2000\n",
      "Images flipped: 3000\n",
      "Images flipped: 4000\n",
      "Images flipped: 5000\n",
      "Images flipped: 6000\n"
     ]
    }
   ],
   "source": [
    "x1, y1 = flipBatchImg(X[select,], y[select,])\n",
    "X = np.concatenate((X,x1))\n",
    "y = np.concatenate((y,y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34125, 160, 320, 3)\n",
      "(34125,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27300 samples, validate on 6825 samples\n",
      "Epoch 1/5\n",
      "27300/27300 [==============================] - 3729s 137ms/step - loss: 0.0366 - val_loss: 0.0478\n",
      "Epoch 2/5\n",
      "27300/27300 [==============================] - 3692s 135ms/step - loss: 0.0281 - val_loss: 0.0384\n",
      "Epoch 3/5\n",
      "27300/27300 [==============================] - 3732s 137ms/step - loss: 0.0253 - val_loss: 0.0396\n",
      "Epoch 4/5\n",
      "27300/27300 [==============================] - 3707s 136ms/step - loss: 0.0233 - val_loss: 0.0388\n",
      "Epoch 5/5\n",
      "27300/27300 [==============================] - 3710s 136ms/step - loss: 0.0204 - val_loss: 0.0414\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Data preprocessing. \n",
    "## normalize. Improve substantially\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5, input_shape = (160,320,3)) )\n",
    "\n",
    "## Cropping. Remove top 70 pixels and bottom 25 pixels\n",
    "model.add(Cropping2D(cropping = ((70,25), (0,0))))\n",
    "\n",
    "# MyNet architecture\n",
    "model.add(Conv2D(9, (10,10), padding='valid', activation = \"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# 5x5 convolution, 6 filters\n",
    "model.add(Conv2D(27, (6,6), padding='valid', activation = None))\n",
    "model.add(Conv2D(81, (3,3), padding='valid', activation = \"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# Flat layer \n",
    "model.add(Flatten())\n",
    "\n",
    "# relu(xw +b)\n",
    "model.add(Dense(150, activation = \"relu\"))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "\n",
    "model.fit(X, y, validation_split=0.2, shuffle=True, epochs = 5)\n",
    "model.save(\"model1.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)    (None, 65, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 56, 311, 9)        2709      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 28, 155, 9)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 23, 150, 27)       8775      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 148, 81)       19764     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 74, 81)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 59940)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               8991150   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                7550      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 9,029,999\n",
      "Trainable params: 9,029,999\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# # reload model\n",
    "# from keras.models import load_model\n",
    "# model1 = load_model(\"model1.h5\")\n",
    "\n",
    "# model1.fit(X, y, validation_split=0.2, shuffle=True, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27300 samples, validate on 6825 samples\n",
      "Epoch 1/5\n",
      "  544/27300 [..............................] - ETA: 59:40 - loss: 0.0169"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-0038eef7f7e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistory_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# history_object = model.fit_generator(train_generator, samples_per_epoch =len(train_samples),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#                                      validation_data = validation_generator,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Visualize Loss\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_object = model.fit(X, y, validation_split=0.2, shuffle=True, epochs = 5, verbose=1)\n",
    "# history_object = model.fit_generator(train_generator, samples_per_epoch =len(train_samples), \n",
    "#                                      validation_data = validation_generator, \n",
    "#                                      nb_val_samples = len(validation_samples), nb_epoch=5, verbose=1)\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('Model Mean Squared Error (MSE) loss')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training set', 'Validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
